<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cheng's Blog</title><link href="/" rel="alternate"></link><link href="/feeds/domain.atom.xml" rel="self"></link><id>/</id><updated>2014-10-01T22:00:00+08:00</updated><entry><title>图像识别</title><link href="/.html" rel="alternate"></link><updated>2014-10-01T22:00:00+08:00</updated><author><name>Cheng</name></author><id>tag:,2014-10-01:.html</id><summary type="html">&lt;h2&gt;图像检索的相关背景&lt;/h2&gt;
&lt;p&gt;从难易程度和发展顺序,不同的研究方向上大致上可以将图像检索划分为这么几个阶段&lt;br /&gt;
1. 基于文本的关键字搜索图像（CBIR） – 淘宝: 搜索”帽子”, 得到与帽子相关的图片产品&lt;br /&gt;
2. 基于内容的图像搜索（TBIR） – 淘宝：输入你喜欢的图片, 找到同款的产品&lt;br /&gt;
3. 基于语义的图像检索/图像识别 – 淘宝: 随手拍下喜欢帽子的图片, 通过搜索就能够找到同款或相似的额产品&lt;/p&gt;
&lt;h2&gt;阶段一 基于文本关键字搜索图像 (Text-based Image Retrieval)&lt;/h2&gt;
&lt;p&gt;相对普通的用例，用户输入文本关键字, 根据预定义的索引, 查找相对应的图片&lt;br /&gt;
1. 特征类别分化，图片库 --&amp;gt; 图片特征库 --&amp;gt; 关键字 类别 输入 匹配 检索结果
没有太多可以讨论的, 关键在于根据图片建立反向关键词索引的过程.&lt;/p&gt;
&lt;h2&gt;阶段二 反向图像搜索/基于内容的图像搜索 (Reverse Image Search /content-based image retrieval)&lt;/h2&gt;
&lt;p&gt;基于内容的图像检索技术利用图像本身就有的物理信息，通过对图像的颜色、纹理、形状和空间位置等特征进行比较，在一些特定的领域得到了大量的应用。 
从程序过程上来看， 可以分为如下： 图片特征值提取 --&amp;gt; 图片特征库 --&amp;gt; 待识别图片 特征提取 匹配 检索结果。&lt;br /&gt;
目前图像识别搜索采用的算法大都直接使用或者借鉴了SIFT， 通过定义一些的特征点或者说是指纹（颜色，纹理，形状特征）来取得图像文件的特征值。图片指纹并不能达到图片在视觉上的相似性搜索，当然它可适用于比较精准的搜索.  &lt;/p&gt;
&lt;h5&gt;罗列下常见的算法：&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;SIFT(Scale-invariant feature transform), Lowe, 1999 -- 分析提取图像中的向量特征点进行匹配  &lt;/li&gt;
&lt;li&gt;PCA-SIFT(Principle Component Analysis)  &lt;/li&gt;
&lt;li&gt;SURF(Speeded Up Robust Features)  &lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;一些基于反向搜索的商业案例:&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;http://tineye.com – 基于图片的指纹&lt;/li&gt;
&lt;li&gt;http://www.tiltomo.com -- flickr 主题风格的色调和机制&lt;/li&gt;
&lt;li&gt;http://www.incogna.com -- 色彩和形状上的相似性&lt;/li&gt;
&lt;li&gt;http://www.terragalleria.com -- 视觉上的相似性&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;阶段三 图像识别 (Image Recognition)&lt;/h2&gt;
&lt;p&gt;更为广泛的图像检索（也称这为基于内容的图像检索），是希望能返回与查询图像在视觉上相似的图像而非要一模一样的内容。 纯粹的逆向图片搜索， 只能帮助找到特征值逼近相同的图片， 并无法分类解释图片当中的具体内容。而更为高级的图片是要建立高层的语义特征而非简单的颜色、纹理、形状等低层特征。&lt;br /&gt;
Google利用了其原有的庞大的文本数据库， 为图像反查和文本搜索引擎的结合; 首先查询和原图相关的图片,再从全文搜索引擎猜测相关的内容。换句话说, 通过其web的上下文信息来反补了其原本不足的语义。&lt;br /&gt;
Google的方式：找到原图、认出图中是什么、找到类似的图、找到相关网页。
举个例子: 依据蘑菇的图片进行搜索&lt;/p&gt;
&lt;h5&gt;上图的内容分别为:&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;找到原图&lt;/li&gt;
&lt;li&gt;认出图中是什么&lt;/li&gt;
&lt;li&gt;找到类似的图&lt;/li&gt;
&lt;li&gt;找到相关的网页&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;思考一下此类方案的局限性 ，在于你用来搜索的原图片，是网上已有的，而不是自己拍摄的实物。试图在网上搜索出自己刚拍的一张照片里面究竟是什么东西，这种技术还处于极其原始的状态。&lt;br /&gt;
目前只能做到对照片中外观特征十分明显的对象做初步的模式识别，并辅以人工验证。
比如交通摄像头，对车牌这个方方正正的大蓝框和里面的大白字进行识别，然后让交警亲自比对，才能认定一个车牌号是否正确；&lt;br /&gt;
日常生活中更常见的二维码、条码、指纹识别、文字OCR，无一不是特征极其明显，而且拍摄时还要特意摆正对准。&lt;br /&gt;
换句话说,复杂图像的图像识别技术还处于很原始的阶段。  &lt;/p&gt;
&lt;h2&gt;综述&lt;/h2&gt;
&lt;p&gt;//todo&lt;/p&gt;
&lt;h2&gt;资料引用&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;图像检索技术进展综述 -- 甘晨，易法令，王圆妹  长江大学计算机科学学院 434023&lt;/li&gt;
&lt;li&gt;http://en.wikipedia.org/wiki/Scale-invariant_feature_transform -- SIFT 基本介绍&lt;/li&gt;
&lt;li&gt;http://leafsnap.com/ --有意思的app, 拍摄植物的一枚叶子、花，果实或种子，app会分析告诉你这是什么植物。&lt;/li&gt;
&lt;li&gt;http://www.ipol.im/pub/pre/82/ -- The Anatomy of the SIFT Method&lt;/li&gt;
&lt;li&gt;//todo&lt;/li&gt;
&lt;/ol&gt;</summary><category term=""></category></entry></feed>